{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##  EECP0020 - LINGUAGENS FORMAIS E AUTÔMATOS (2024 .1 - T01)\n",
        "PROJETO GRUPO 2\n"
      ],
      "metadata": {
        "id": "LNCy3Nlyl_ca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXEMPLO INICIAL"
      ],
      "metadata": {
        "id": "aG8WVrNXnsIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class SentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.positive_patterns = [\n",
        "            r'excelente',\n",
        "            r'ótimo',\n",
        "            r'maravilhoso',\n",
        "            r'incrível'\n",
        "        ]\n",
        "        self.negative_patterns = [\n",
        "            r'péssimo',\n",
        "            r'ruim',\n",
        "            r'horrível',\n",
        "            r'desastroso',\n",
        "            r'insatisfeito'\n",
        "        ]\n",
        "\n",
        "    def analyze_sentiment(self, text):\n",
        "        positive_score = self._calculate_score(text, self.positive_patterns)\n",
        "        negative_score = self._calculate_score(text, self.negative_patterns)\n",
        "\n",
        "        if positive_score > negative_score:\n",
        "            return \"Positive\"\n",
        "        elif positive_score < negative_score:\n",
        "            return \"Negative\"\n",
        "        else:\n",
        "            return \"Neutral\"\n",
        "\n",
        "    def _calculate_score(self, text, patterns):\n",
        "        score = 0\n",
        "        for pattern in patterns:\n",
        "            score += len(re.findall(pattern, text, re.IGNORECASE))\n",
        "        return score\n",
        "\n",
        "# Exemplo de uso\n",
        "analyzer = SentimentAnalyzer()\n",
        "text = \"O produto é horrível, estou muito insatisfeito!\"\n",
        "sentiment = analyzer.analyze_sentiment(text)\n",
        "print(\"Sentimento:\", sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr_flo0GYIWC",
        "outputId": "bccc6c02-beba-4fd8-b58a-8a54ebb92f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentimento: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PROJETO"
      ],
      "metadata": {
        "id": "D8wARccBn1DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews') # baixando dados iniciais\n",
        "nltk.download('stopwords') # baixando conjunto de stopwords\n",
        "nltk.download('punkt') # baixando modelo treinável não supervisionado"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fMLsOV75V3x",
        "outputId": "dc3a446e-3bd3-41f4-efa1-748bf1cc76e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.classify import accuracy"
      ],
      "metadata": {
        "id": "Fwqnunq_L075"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_reviews.categories()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL66hAAme1O3",
        "outputId": "fb99b876-d518-46f1-f853-0fff4e64a3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg', 'pos']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(movie_reviews.fileids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVjP8nYErAxY",
        "outputId": "58ab24aa-c4e0-42e6-9b72-fcda9575a09a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_neg = len(movie_reviews.fileids(categories='neg'))\n",
        "num_pos = len(movie_reviews.fileids(categories='pos'))\n",
        "\n",
        "print(\"Quantidades de reviews positivos: \", num_pos)\n",
        "print(\"Quantidades de reviews negativos: \", num_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCBeq-6Xhb4R",
        "outputId": "22b9336a-cd99-44d2-a1e5-7b0a642d576a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidades de reviews positivos:  1000\n",
            "Quantidades de reviews negativos:  1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cu29Kqq95BMa"
      },
      "outputs": [],
      "source": [
        "class SentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        # Carrega as resenhas de filmes da biblioteca NLTK\n",
        "        self.documents = [(list(movie_reviews.words(fileid)), category)\n",
        "                         for category in movie_reviews.categories()\n",
        "                         for fileid in movie_reviews.fileids(category)]\n",
        "        random.shuffle(self.documents)\n",
        "\n",
        "        # Pré-processamento de texto\n",
        "        all_words = [word.lower() for word in movie_reviews.words()]\n",
        "        self.all_words = [word for word in all_words if word.isalpha()]\n",
        "        self.all_words = [word for word in self.all_words if word not in stopwords.words('english')]\n",
        "        self.all_words = FreqDist(self.all_words)\n",
        "        self.word_features = list(self.all_words.keys())\n",
        "\n",
        "        # Cria um conjunto de características para cada resenha\n",
        "        self.featuresets = [(self.find_features(rev), category) for (rev, category) in self.documents]\n",
        "\n",
        "        # Divide o conjunto de dados em treinamento e teste\n",
        "        self.train_set, self.test_set = train_test_split(self.featuresets, test_size=0.25)\n",
        "\n",
        "        # Treina o classificador\n",
        "        self.classifier = SklearnClassifier(MultinomialNB())\n",
        "        self.classifier.train(self.train_set)\n",
        "\n",
        "    def find_features(self, document):\n",
        "        words = set(document)\n",
        "        features = {}\n",
        "        for w in self.word_features:\n",
        "            features[w] = (w in words)\n",
        "        return features\n",
        "\n",
        "    def analyze_sentiment(self, text):\n",
        "        # Pré-processamento do texto de entrada\n",
        "        words = word_tokenize(text.lower(), language='english')\n",
        "        words = [word for word in words if word.isalpha()]\n",
        "        words = [word for word in words if word not in stopwords.words('english')]\n",
        "\n",
        "        # Extraindo características do texto de entrada\n",
        "        features = self.find_features(words)\n",
        "\n",
        "        # Classificando o sentimento usando o classificador treinado\n",
        "        sentiment = self.classifier.classify(features)\n",
        "        return sentiment\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        # Avaliando a acurácia do modelo usando o conjunto de teste\n",
        "        accuracy_score = accuracy(self.classifier, self.test_set)\n",
        "        return accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso\n",
        "if __name__ == \"__main__\":\n",
        "    # Inicializando o analisador de sentimentos\n",
        "    analyzer = SentimentAnalyzer()\n",
        "\n",
        "    # Textos de exemplo\n",
        "    texts = [\n",
        "       \"I loved the new movie!\",\n",
        "        \"The customer service was terrible, I will never go back.\",\n",
        "        \"This product is good, but could be better.\",\n",
        "        \"I'm neutral about this book.\",\n",
        "       \"I hated the new movie!\",\n",
        "       \"This was the worst thing I have seen in my entire life. Aesthetics aside, there was nothing. Nothing to say, nothing to comment on. Just mindless amalgamation of scenes that were supposed to engineer some kind of reaction. The only reaction the entire theater had was sighing, cringing, and leaving.\",\n",
        "       \"Am a lifelong sci-fi fan. This one is visually stunning. Has a great plot too. Am pretty easily bored and this one never let my attention lapse. A must see as far as I'm concerned. The special effects on the Simlicants was flawless. The twist of who wants peace and who is the aggressor was also unexpected. Watched Rebel Moon recently and it was a huge disappointment compared to The Creator. The Creator is a unique story and had the look and feel of the Blade Runner movies, at least in the large cities. The rural scenes were also beautiful, as were the water towns. I bought the blu ray and it will get watched again in the future.\"\n",
        "    ]\n",
        "\n",
        "    # Analisando sentimentos para cada texto de exemplo\n",
        "    for text in texts:\n",
        "        sentiment = analyzer.analyze_sentiment(text)\n",
        "        print(f\"Texto: '{text}'\\nSentimento: {sentiment}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wevC6kaaNxAh",
        "outputId": "251413c6-42ab-49c4-d61e-4571cafd835d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto: 'I loved the new movie!'\n",
            "Sentimento: pos\n",
            "\n",
            "Texto: 'The customer service was terrible, I will never go back.'\n",
            "Sentimento: neg\n",
            "\n",
            "Texto: 'This product is good, but could be better.'\n",
            "Sentimento: neg\n",
            "\n",
            "Texto: 'I'm neutral about this book.'\n",
            "Sentimento: pos\n",
            "\n",
            "Texto: 'I hated the new movie!'\n",
            "Sentimento: neg\n",
            "\n",
            "Texto: 'This was the worst thing I have seen in my entire life. Aesthetics aside, there was nothing. Nothing to say, nothing to comment on. Just mindless amalgamation of scenes that were supposed to engineer some kind of reaction. The only reaction the entire theater had was sighing, cringing, and leaving.'\n",
            "Sentimento: neg\n",
            "\n",
            "Texto: 'Am a lifelong sci-fi fan. This one is visually stunning. Has a great plot too. Am pretty easily bored and this one never let my attention lapse. A must see as far as I'm concerned. The special effects on the Simlicants was flawless. The twist of who wants peace and who is the aggressor was also unexpected. Watched Rebel Moon recently and it was a huge disappointment compared to The Creator. The Creator is a unique story and had the look and feel of the Blade Runner movies, at least in the large cities. The rural scenes were also beautiful, as were the water towns. I bought the blu ray and it will get watched again in the future.'\n",
            "Sentimento: pos\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accurary_model = analyzer.evaluate_model()\n",
        "print(\"Acurácia do Modelo: \", accurary_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdFgCT7qpVli",
        "outputId": "f499b8a0-a099-4833-9244-2338113d96b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do Modelo:  0.83\n"
          ]
        }
      ]
    }
  ]
}