\section{Introdução}\label{sec:introducao}

As recentes evoluções em modelos de linguagem de grande porte (LLMs) tornaram a assistência à escrita acadêmica uma prática acessível a estudantes universitários, com efeitos ainda em consolidação sobre processos de planejamento, rascunho, revisão e reescrita. Estudos empíricos têm identificado traços estilísticos e mudanças na seleção vocabular associados ao uso de LLMs, sugerindo que intervenções algorítmicas deixam marcas detectáveis em textos acadêmicos \cite{kobak2025llm}. Em paralelo, há indícios de alteração de estilo e densidade textual quando pesquisadores e estudantes utilizam sistemas generativos, com potenciais ganhos de fluência e organização, mas também com riscos de homogeneização e redução de variação estilística \cite{geng2024style,yeadon2024ai}. No ecossistema editorial, editoriais e posicionamentos institucionais têm estabelecido balizas para o uso transparente e ético de ferramentas de IA na comunicação científica \cite{thorp2023notauthor,nature2023groundrules,cope2023ai,wame2023recs,icmje2023ai}.

Do ponto de vista pedagógico, a IA generativa desponta como apoio para feedback imediato sobre estrutura, coesão e correção linguística, possibilitando ciclos de revisão mais curtos e maior atenção a aspectos retóricos do texto. Diretrizes internacionais destacam oportunidades para promover autorregulação da escrita, planejamento mais explícito e desenvolvimento de competências metacognitivas por meio de prompts e tarefas cuidadosamente mediadas \cite{unesco2023diretrizes,educause2023gai}. Em cursos que exigem produção textual intensiva, relatam-se benefícios ligados à ampliação do repertório lexical, à reorganização de argumentos e ao esclarecimento de convenções acadêmicas, quando o uso é orientado e crítico \cite{yeadon2024ai}. Ao mesmo tempo, a literatura alerta para riscos pedagógicos como dependência excessiva de sugestões superficiais, aderência acrítica a padrões discursivos genéricos e deslocamento do foco do conteúdo para a forma \cite{geng2024style}.

No âmbito da integridade acadêmica, organizações editoriais e comitês de ética convergem na necessidade de explicitar o uso de ferramentas de IA, vedar a atribuição de autoria a sistemas e estabelecer critérios para responsabilização humana sobre a precisão e a originalidade do conteúdo \cite{cope2023ai,wame2023recs,icmje2023ai,thorp2023notauthor}. Tais documentos enfatizam transparência de uso, documentação de versões e revisão humana substantiva, bem como cautela com alucinações, vieses e referências fabricadas. Em termos de avaliação, Nature e outras revistas propõem regras claras para submissões que envolvam IA, reforçando que a validação metodológica e a checagem factual permanecem prerrogativas de autores humanos \cite{nature2023groundrules}.

Apesar dos avanços, persistem lacunas relevantes à realidade de estudantes de graduação, especialmente em contextos lusófonos: ainda são escassas as investigações controladas que mensurem impactos de LLMs na qualidade argumentativa em língua portuguesa, nas diferentes áreas do conhecimento, e que distingam entre ganhos de forma (fluência, microestrutura) e de conteúdo (profundidade analítica, precisão conceitual). Carecem, ademais, estudos sobre os efeitos de longo prazo do uso assistido na autonomia escritora e na transferência de aprendizados para tarefas sem suporte de IA. Do ponto de vista institucional, políticas internas de cursos e universidades ainda variam amplamente, com graus distintos de orientação, mediação docente e protocolos de transparência \cite{unesco2023diretrizes,cope2023ai}.

Outra frente pouco explorada envolve a metacognição: em que medida a interação com LLMs estimula planejamento, monitoramento e avaliação da própria escrita, e quando ela encoraja atalhos que reduzem o esforço cognitivo necessário à construção de conhecimento? Relatos iniciais apontam que o desenho de atividades e rubricas, aliado a orientações explícitas de uso, é determinante para que a tecnologia funcione como \'andame\' e não como substituto do raciocínio \citeonline{educause2023gai}. Em avaliação, permanecem desafios de detecção e atribuição, com ferramentas ainda pouco confiáveis para identificar trechos gerados por IA e com risco de falsos positivos que penalizam estudantes injustamente \cite{kobak2025llm}.

À luz desse panorama, este trabalho situa a investigação no cruzamento entre potencial formativo e salvaguardas de integridade: descrevemos como o uso responsável de IA pode favorecer processos de revisão e desenvolvimento de competências de escrita, sem abdicar de transparência, autoria humana e checagem rigorosa. À luz dessa discussão, a questão de pesquisa é explicitada na sequência deste trabalho.
